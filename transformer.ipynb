{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ruff in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from -r tic-tac-toe/requirements.txt (line 1)) (0.9.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from -r tic-tac-toe/requirements.txt (line 2)) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from -r tic-tac-toe/requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from -r tic-tac-toe/requirements.txt (line 6)) (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (8.32.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (6.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (5.2.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (308)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\spencer\\anaconda3\\envs\\tic\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r tic-tac-toe/requirements.txt (line 6)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///C:/Users/Spencer/Documents/CUBoulder/CSCI7000/Assignment1/tic-tac-toe\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: tictactoe\n",
      "  Building editable for tictactoe (pyproject.toml): started\n",
      "  Building editable for tictactoe (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tictactoe: filename=tictactoe-0.0.1-0.editable-py3-none-any.whl size=2824 sha256=ff40b4e98f2ff73fc762ad2aabb18d8d62a656459ca08e5825e514ace5b6c268\n",
      "  Stored in directory: C:\\Users\\Spencer\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-76c2cwem\\wheels\\d6\\5a\\8d\\feebe8c7295a76526ef50a01375931f6375dbc01f17aab1db7\n",
      "Successfully built tictactoe\n",
      "Installing collected packages: tictactoe\n",
      "  Attempting uninstall: tictactoe\n",
      "    Found existing installation: tictactoe 0.0.1\n",
      "    Uninstalling tictactoe-0.0.1:\n",
      "      Successfully uninstalled tictactoe-0.0.1\n",
      "Successfully installed tictactoe-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r tic-tac-toe/requirements.txt\n",
    "%pip install -e tic-tac-toe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tictactoe.board import Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "- Create Data\n",
    "    - Create Recursive function to get all board positions\n",
    "    - Create Function to get best move\n",
    "- Create Transformer\n",
    "- Train Transformer\n",
    "- Write article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1 j: 0 board:[[ 0  1  1]\n",
      " [-1 -1  0]\n",
      " [-1 -1  1]]\n",
      "i: 2 j: 2 board:[[ 0  1  1]\n",
      " [ 0 -1  0]\n",
      " [-1 -1  1]]\n",
      "i: 1 j: 1 board:[[ 0  1  1]\n",
      " [ 0 -1  0]\n",
      " [-1 -1  0]]\n",
      "i: 0 j: 1 board:[[ 0  1  1]\n",
      " [ 0  0  0]\n",
      " [-1 -1  0]]\n",
      "i: 2 j: 0 board:[[ 0  0  1]\n",
      " [ 0  0  0]\n",
      " [-1 -1  0]]\n",
      "i: 0 j: 2 board:[[ 0  0  1]\n",
      " [ 0  0  0]\n",
      " [ 0 -1  0]]\n",
      "i: 2 j: 1 board:[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0 -1  0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[357], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m j: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m board:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_board\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[357], line 22\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     20\u001b[0m new_board \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mboard\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_board\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m j: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m board:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_board\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[357], line 22\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     20\u001b[0m new_board \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mboard\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_board\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m j: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m board:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_board\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[1;31m[... skipping similar frames: generate_data at line 22 (4 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[357], line 22\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     20\u001b[0m new_board \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mboard\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_board\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m j: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m board:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_board\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[357], line 5\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_data\u001b[39m(board):\n\u001b[0;32m      4\u001b[0m     b \u001b[38;5;241m=\u001b[39m Board()\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray2string(\u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(boards\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(board \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m         out_boards \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b\u001b[38;5;241m.\u001b[39mget_best_moves(board)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "boards = {}\n",
    "def generate_data(board):\n",
    "    b = Board()\n",
    "    if np.array2string(board.flatten()) not in list(boards.keys()):\n",
    "        out_boards = []\n",
    "        for i,j in b.get_best_moves(board):\n",
    "            nb = Board()\n",
    "            nb.set_board(np.copy(board))\n",
    "            nb.place(i,j)\n",
    "            out_boards.append(nb.to_str())\n",
    "        boards[np.array2string(board.flatten())] = out_boards\n",
    "\n",
    "    for i, j in list(zip(*np.where(board==0))):\n",
    "        nb = Board()\n",
    "        nb.set_board(np.copy(board))\n",
    "        nb.place(i,j)\n",
    "        new_board = nb.board\n",
    "        try:\n",
    "            generate_data(new_board)\n",
    "        except:\n",
    "            print(f\"i: {i} j: {j} board:{new_board}\")\n",
    "            raise\n",
    "generate_data(np.array([[0,0,0],\n",
    "                        [0,0,0],\n",
    "                        [0,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_data = {k:v for k, v in data.items() if v != []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(boards.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_key: [0 0 0 0 0 0 0 0 0] \n",
      " ex_vals: ['[-1  0  0  0  0  0  0  0  0]', '[ 0 -1  0  0  0  0  0  0  0]', '[ 0  0 -1  0  0  0  0  0  0]', '[ 0  0  0 -1  0  0  0  0  0]', '[ 0  0  0  0 -1  0  0  0  0]', '[ 0  0  0  0  0 -1  0  0  0]', '[ 0  0  0  0  0  0 -1  0  0]', '[ 0  0  0  0  0  0  0 -1  0]', '[ 0  0  0  0  0  0  0  0 -1]']\n"
     ]
    }
   ],
   "source": [
    "ex_key = list(boards.keys())[0]\n",
    "print(f\"ex_key: {ex_key} \\n ex_vals: {boards[ex_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/data.json', 'w') as f:\n",
    "    json.dump(fixed_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5920"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_percent, val_percent, test_percent = 0.7, 0.2, 0.1\n",
    "\n",
    "data_keys = list(data.keys())\n",
    "n = len(data_keys)\n",
    "num_train, num_val, num_test = int(train_percent*n), int(val_percent*n), int(test_percent*n)\n",
    "\n",
    "select_train = random.sample(data_keys, num_train)\n",
    "val_and_test = [value for value in data_keys if value not in select_train]\n",
    "\n",
    "select_val = random.sample(val_and_test, num_val)\n",
    "select_test = [value for value in val_and_test if value not in select_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boards_to_format(key):\n",
    "    key = key[1:-1]\n",
    "    return [int(c) for c in key.split(' ') if c in ['-1', '0', '1']]\n",
    "\n",
    "train_data = {int(i): (boards_to_format(k), [boards_to_format(v) for v in data[k]]) for i, k in enumerate(select_train)}\n",
    "val_data = {int(i): (boards_to_format(k), [boards_to_format(v) for v in data[k]]) for i, k in enumerate(select_val)}\n",
    "test_data = {int(i): (boards_to_format(k), [boards_to_format(v) for v in data[k]]) for i, k in enumerate(select_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144\n",
      "1184\n",
      "592\n"
     ]
    }
   ],
   "source": [
    "print(len(list(train_data.keys())))\n",
    "print(len(list(val_data.keys())))\n",
    "print(len(list(test_data.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "with open('./data/val.json', 'w') as f:\n",
    "    json.dump(val_data, f)\n",
    "with open('./data/test.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translate Data into dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TicTacDataset(Dataset):\n",
    "    def __init__(self, path = './data/train.json'):\n",
    "        with open(path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.len = len(list(self.data.keys()))\n",
    "        \n",
    "        # self.inputs, self.outputs = [], []\n",
    "        # for ins, outs in data.items():\n",
    "        #     for out in outs:\n",
    "        #         self.inputs.append(self.boards_to_format(ins))\n",
    "        #         self.outputs.append(self.boards_to_format(out))\n",
    "\n",
    "    # def boards_to_format(self, key):\n",
    "    #     key = key[1:-1]\n",
    "    #     return [int(c) for c in key.split(' ') if c in ['-1', '0', '1']]\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ins, outs = self.data[str(idx)]\n",
    "        return ins, outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TicTacDataset(path='./data/train.json')\n",
    "val_dataset = TicTacDataset(path='./data/val.json')\n",
    "test_dataset = TicTacDataset(path='./data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    # print(batch)\n",
    "    ins = [torch.tensor(b[0])+1 for b in batch]\n",
    "    outs = [torch.tensor(np.average(np.array(b[1])+1, axis=0)) for b in batch]\n",
    "    # print(outs)\n",
    "\n",
    "\n",
    "\n",
    "    # max_outs = max([len(o) for o in outs])\n",
    "    # padded_outs = []\n",
    "    # for o in outs:\n",
    "    #   pad_boxes = max_outs - len(o)\n",
    "    #   padded_out = (o) + [[1,1,1,1,1,1,1,1,1]] * pad_boxes\n",
    "    #   padded_outs.append(torch.tensor(padded_out, dtype=torch.float32)+1)\n",
    "    return torch.stack(ins), torch.stack(outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set default device to CUDA if available, otherwise CPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "else:\n",
    "    torch.set_default_device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 3\n",
    "num_embedding = 32\n",
    "\n",
    "num_heads = 8\n",
    "\n",
    "num_blocks = 4\n",
    "block_size = 9\n",
    "\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" Singular Head\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(num_embedding, head_size, bias=False)\n",
    "        self.query = nn.Linear(num_embedding, head_size, bias=False)\n",
    "        self.value = nn.Linear(num_embedding, head_size, bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "\n",
    "        k = self.key(x) # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "\n",
    "        # Computer attention\n",
    "        # C**0.5 is to make the numbers smaller so softmax doesn't do weird things\n",
    "        wei = q @ k.transpose(-2, -1) / C**0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # \n",
    "        V = self.value(x)\n",
    "        out = wei @ V # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multiple Attention Heads\"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for i in range(num_heads)])\n",
    "        self.project = nn.Linear(num_embedding, num_embedding)                  # Projection layer for gettting back into the residual pathway\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.project(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\"Single Layer\"\"\"\n",
    "\n",
    "    def __init__(self, num_embedding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.m = nn.Sequential(nn.Linear(num_embedding, 4 * num_embedding), # 4* because they did it in the paper\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(4 * num_embedding, num_embedding), # Projection layer for gettting back into the residual pathway\n",
    "                               nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(self, num_embedding, num_head):\n",
    "        super().__init__()\n",
    "\n",
    "        head_size = num_embedding // num_head\n",
    "        self.self_attn = MultiHeadAttention(num_head, head_size)\n",
    "        self.feed_fwd = FeedFoward(num_embedding)\n",
    "\n",
    "        self.lay_norm1 = nn.LayerNorm(num_embedding)\n",
    "        self.lay_norm2 = nn.LayerNorm(num_embedding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.self_attn(self.lay_norm1(x))\n",
    "        x = x + self.feed_fwd(self.lay_norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,num_embedding)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, num_embedding)\n",
    "\n",
    "        # Attention\n",
    "        self.attn_blocks = nn.Sequential(\n",
    "            *[Block(num_embedding, num_head = 4) for i in range(num_blocks)],\n",
    "            nn.LayerNorm(num_embedding),\n",
    "        )\n",
    "\n",
    "        self.lm_head = nn.Linear(num_embedding, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        B, T = inputs.shape\n",
    "        print(inputs[0])\n",
    "        print(labels[0])\n",
    "\n",
    "        token_embedding = self.token_embedding_table(inputs) # (B, T, C)\n",
    "        position_embedding = self.position_embedding_table(torch.arange(T)) # (T, C)\n",
    "        x = token_embedding + position_embedding # (B, T, C)\n",
    "\n",
    "        x = self.attn_blocks(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            print(logits.shape)\n",
    "            print(labels.shape)\n",
    "            \n",
    "            # loss = F.cross_entropy(logits, labels) # need to add \n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 1, 2, 0, 1, 1, 0])\n",
      "tensor([1.0000, 2.0000, 0.5000, 1.0000, 2.0000, 0.0000, 1.0000, 0.5000, 0.0000],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([64, 9, 3])\n",
      "torch.Size([64, 9])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [64, 3], got [64, 9]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[419], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batched_x, batched_y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m----> 9\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[418], line 34\u001b[0m, in \u001b[0;36mTicTacToeModel.forward\u001b[1;34m(self, inputs, labels)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# need to add \u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, loss\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\nn\\functional.py:3480\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3414\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[0;32m   3415\u001b[0m \n\u001b[0;32m   3416\u001b[0m \u001b[38;5;124;03mSee :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;124;03m    >>> loss.backward()\u001b[39;00m\n\u001b[0;32m   3478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n\u001b[1;32m-> 3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\overrides.py:1720\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1720\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1722\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\utils\\_device.py:104\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Spencer\\anaconda3\\envs\\tic\\lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [64, 3], got [64, 9]"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "model = TicTacToeModel()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batched_x, batched_y in train_dataloader:\n",
    "        logits, loss = model(batched_x, batched_y)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    for xenc_batch, y_batch, lengths in dataloader:\n",
    "\n",
    "        # Move batch to GPU\n",
    "        xenc_batch = xenc_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = xenc_batch @ W  # Log-counts, shape: [batch_size, max_seq_len, alphabet_size]\n",
    " \n",
    "        logits = logits.view(-1, logits.size(-1))  # Shape: [batch_size * max_seq_len, vocab_size]\n",
    "        y_batch = y_batch.view(-1)  # Shape: [batch_size * max_seq_len]\n",
    "\n",
    "        # Compute the loss using CrossEntropyLoss\n",
    "        loss = F.cross_entropy(logits, y_batch, ignore_index=ctoi['.'])\n",
    "        \n",
    "        # Backward pass\n",
    "        W.grad = None  # Set gradients to zero before backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights (gradient descent)\n",
    "        with torch.no_grad():  # Don't track this update in the graph\n",
    "            W -= 5 * W.grad  # Gradient update\n",
    "        xloss.append(loss.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
